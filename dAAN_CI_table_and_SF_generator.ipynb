{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2babb915",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import math\n",
    "import os \n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "import csv \n",
    "import xlsxwriter\n",
    "import scipy\n",
    "from sklearn.metrics import r2_score\n",
    "from dipy.io.image import load_nifti, save_nifti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d189bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique(list1): \n",
    "    # initialize a null list\n",
    "    unique_list = []\n",
    "  \n",
    "    # traverse for all elements\n",
    "    for x in list1:\n",
    "        # check if exists in unique_list or not\n",
    "        if x not in unique_list:\n",
    "            unique_list.append(x)           \n",
    "    return unique_list\n",
    "\n",
    "\n",
    "def calculate_and_create_CI_mat(df):\n",
    "    K1 = df['K1'].tolist()\n",
    "    N1 = df['N1'].tolist()\n",
    "    K2 = df['K2'].tolist()\n",
    "    N2 = df['N2'].tolist() \n",
    "    K1 = np.array(K1)\n",
    "    K2 = np.array(K2)\n",
    "    N1 = np.array(N1)\n",
    "    N2 = np.array(N2)\n",
    "    \n",
    "    N = np.add(N1,N2)\n",
    "    p1 = np.divide(K1,N1)\n",
    "    p2 = np.divide(K2,N2)\n",
    "    \n",
    "    p = (N1*p1 + N2*p2)/N\n",
    "    \n",
    "    var_p = (p*(1-p))/N\n",
    "    \n",
    "    z_score = 1.96   \n",
    "    CI_L = p - z_score*np.sqrt(var_p)\n",
    "    CI_H = p + z_score*np.sqrt(var_p)\n",
    "       \n",
    "    return CI_L, CI_H\n",
    "\n",
    "\n",
    "def create_correlation_matrix(path):\n",
    "    df = pandas.read_excel(path, engine='openpyxl')\n",
    "    \n",
    "    print(\"found: \", df.columns.ravel())\n",
    "    names = df['SEED2TARGET'].tolist()\n",
    "    cps_raw = df['CPab'].tolist()\n",
    "    \n",
    "    seeds = []\n",
    "    targets = []\n",
    "    vals = []\n",
    "\n",
    "    for i in range(0,len(names)):\n",
    "        test_str = names[i]\n",
    "        substring = '_2022'\n",
    "        first = test_str.split(substring)[0]\n",
    "        substring2 = '.2.'\n",
    "        second = test_str.split(substring2)[1]\n",
    "        third = second.split(substring)[0]\n",
    "        seeds.append(first)\n",
    "        targets.append(third)\n",
    "        vals.append(cps_raw[i]*100)    # probably not a percent but raw val\n",
    "        \n",
    "        \n",
    "    unique_seeds = unique(seeds)\n",
    "    unique_seeds.sort()\n",
    "    cp_mat = np.zeros((len(unique_seeds),len(unique_seeds)), float)\n",
    "    cp_stats_mat = np.zeros((len(unique_seeds),len(unique_seeds)), float)\n",
    "    \n",
    "    CI_L_mat = np.zeros((len(unique_seeds),len(unique_seeds)), float)\n",
    "    CI_H_mat = np.zeros((len(unique_seeds),len(unique_seeds)), float)\n",
    "    \n",
    "    CI_L, CI_H = calculate_and_create_CI_mat(df) \n",
    "    print(\"dims of CI are: \", CI_L.shape)\n",
    "    \n",
    "    # to get CP_ab map \n",
    "    for i in range(0,len(seeds)):\n",
    "        sd = seeds[i]\n",
    "        targ = targets[i]\n",
    "        val = vals[i]\n",
    "\n",
    "        ind1 = unique_seeds.index(sd)\n",
    "        ind2 = unique_seeds.index(targ)\n",
    "        cp_mat[ind1,ind2] = val\n",
    "        \n",
    "        #### parse out confidence intervals of each element \n",
    "        ci_l_val = CI_L[i]\n",
    "        ci_h_val = CI_H[i]\n",
    "        CI_L_mat[ind1,ind2] = ci_l_val\n",
    "        CI_H_mat[ind1,ind2] = ci_h_val\n",
    "        \n",
    "    for i in range(cp_mat.shape[0]):\n",
    "        for j in range(cp_mat.shape[1]):           \n",
    "            CI_L_ab = CI_L_mat[i,j]\n",
    "            CI_H_ab = CI_H_mat[i,j]\n",
    "              \n",
    "            CI_L_a_bp = CI_L_mat[i,unique_seeds.index('BP_CENTER')]\n",
    "            CI_H_a_bp = CI_H_mat[i,unique_seeds.index('BP_CENTER')]   \n",
    "            CI_L_a_mcp = CI_L_mat[i,unique_seeds.index('RN_CENTER')] \n",
    "            CI_H_a_mcp = CI_H_mat[i,unique_seeds.index('RN_CENTER')] \n",
    "            CI_L_b_bp = CI_L_mat[j,unique_seeds.index('BP_CENTER')]\n",
    "            CI_H_b_bp = CI_H_mat[j,unique_seeds.index('BP_CENTER')]\n",
    "            CI_L_b_mcp = CI_L_mat[j,unique_seeds.index('RN_CENTER')]\n",
    "            CI_H_b_mcp = CI_H_mat[j,unique_seeds.index('RN_CENTER')]\n",
    "                      \n",
    "            CI_trigger = True\n",
    "            if max(CI_L_ab,CI_L_a_bp) <= min(CI_H_ab,CI_H_a_bp):\n",
    "                CI_trigger = False\n",
    "            if max(CI_L_ab,CI_L_a_mcp) <= min(CI_H_ab,CI_H_a_mcp):\n",
    "                CI_trigger = False\n",
    "            if max(CI_L_ab,CI_L_b_bp) <= min(CI_H_ab,CI_H_b_bp):\n",
    "                CI_trigger = False\n",
    "            if max(CI_L_ab,CI_L_b_mcp) <= min(CI_H_ab,CI_H_b_mcp):\n",
    "                CI_trigger = False\n",
    "                \n",
    "            if CI_trigger == True:\n",
    "                cp_stats_mat[i,j] = 1     # no overlap\n",
    "            else:\n",
    "                cp_stats_mat[i,j] = 0     # overlap!    \n",
    "    return cp_mat, cp_stats_mat, unique_seeds\n",
    "\n",
    "\n",
    "def normalize_and_convert_to_rgba(rgb_list, alpha=255):\n",
    "    # Convert RGB and alpha values to numpy arrays\n",
    "    rgb_array = np.array(rgb_list, dtype=float)\n",
    "    alpha_array = np.full((len(rgb_list), 1), alpha, dtype=float)\n",
    "\n",
    "    # Normalize to the range 0-1\n",
    "    rgb_array /= 255.0\n",
    "    alpha_array /= 255.0\n",
    "\n",
    "    # Convert to RGBA\n",
    "    rgba_array = np.hstack((rgb_array, alpha_array))\n",
    "\n",
    "    return rgba_array.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ad796b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "GENERATE CI calculations and paper-ready table format for dAAN EXC cases\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "n_digits = 6\n",
    "cases = [\"EXC007\",\"EXC012\"]\n",
    "n_cases = len(cases)\n",
    "\n",
    "\n",
    "row_list1 = [\"mRt\", \"VTA\", \"PAG\", \"PTg\", \"DR\", \"PnO\", \"PBC\", \"MnR\", \"LC\", \"LDTg\"]\n",
    "col_list1 = [\"IL\",\"PaV\", \"Ret\"]\n",
    "row_list2 = [\"mRt\", \"VTA\", \"PAG\", \"PTg\", \"DR\", \"PnO\", \"PBC\", \"MnR\", \"LC\", \"LDTg\"]\n",
    "col_list2 = [\"TMN\", \"LHA\", \"SUM\"]\n",
    "row_list3 = [\"mRt\", \"VTA\", \"PAG\", \"PTg\", \"DR\", \"PnO\", \"PBC\", \"MnR\", \"LC\", \"LDTg\"]\n",
    "col_list3 = [\"NDB\", \"BNM_SI\"]\n",
    "row_list4 = [\"mRt_L\", \"PTg_L\", \"PnO_L\", \"PBC_L\", \"LC_L\", \"LDTg_L\"]\n",
    "col_list4 = [\"mRt_L\", \"PTg_L\", \"PnO_L\", \"PBC_L\", \"LC_L\", \"LDTg_L\"]\n",
    "row_list5 = [\"mRt_R\", \"PTg_R\", \"PnO_R\", \"PBC_R\", \"LC_R\", \"LDTg_R\"]\n",
    "col_list5 = [\"mRt_R\", \"PTg_R\", \"PnO_R\", \"PBC_R\", \"LC_R\", \"LDTg_R\"]\n",
    "row_list6 = [\"mRt_L\", \"PTg_L\", \"PnO_L\", \"PBC_L\", \"LC_L\", \"LDTg_L\", \"mRt_R\", \"PTg_R\", \"PnO_R\", \"PBC_R\", \"LC_R\", \"LDTg_R\"]\n",
    "col_list6 = [\"VTA\", \"PAG\", \"DR\", \"MnR\"]\n",
    "row_list7 = [\"mRt_L\", \"PTg_L\", \"PnO_L\", \"PBC_L\", \"LC_L\", \"LDTg_L\"]\n",
    "col_list7 = [\"mRt_R\", \"PTg_R\", \"PnO_R\", \"PBC_R\", \"LC_R\", \"LDTg_R\"]\n",
    "row_list8 = [\"mRt\", \"VTA\", \"PAG\", \"PTg\", \"DR\", \"PnO\", \"PBC\", \"MnR\", \"LC\", \"LDTg\"]\n",
    "col_list8 = [\"DMN_PMC\", \"DMN_MPFC\", \"DMN_IPL\",\"DMN_LT\",\"DMN_MT_L\"]\n",
    "row_list8 = [\"mRt\", \"VTA\", \"PAG\", \"PTg\", \"DR\", \"PnO\", \"PBC\", \"MnR\", \"LC\", \"LDTg\"]\n",
    "col_list8 = [\"DMN_PMC\", \"DMN_MPFC\", \"DMN_IPL\",\"DMN_LT\",\"DMN_MT_L\"]\n",
    "row_list9 = [\"ser\", \"nor\", \"dop\", \"ace\", \"glut\"]\n",
    "col_list9 = [\"DMN\"]\n",
    "row_list10 = [\"VTA\", \"PAG\", \"DR\", \"MnR\"]\n",
    "col_list10 = [\"VTA\", \"PAG\", \"DR\", \"MnR\"]\n",
    "\n",
    "row_list_list = (row_list1,row_list2,row_list3,row_list4,row_list5,row_list6,row_list7,row_list8,row_list10)\n",
    "col_list_list = (col_list1,col_list2,col_list3,col_list4,col_list5,col_list6,col_list7,col_list8,col_list10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### try xlsxwriter with bolded CI pass vals \n",
    "workbook = xlsxwriter.Workbook(\"/Users/markolchanyi/Desktop/table_test_05232023.xlsx\")\n",
    "\n",
    "book_format_true = workbook.add_format(properties={'bold': False, 'font_color': 'black'}))\n",
    "book_format_false = workbook.add_format(properties={'bold': False, 'font_color': 'red'})\n",
    "\n",
    "worksheet = workbook.add_worksheet()\n",
    "\n",
    "\n",
    "row_counter = 0\n",
    "for ind, row_list in enumerate(row_list_list):\n",
    "    \n",
    "\n",
    "    col_list = col_list_list[ind]\n",
    "    \n",
    "    out_array = np.zeros((len(row_list),len(col_list)*(n_cases+1)))\n",
    "    std_array = np.zeros((len(row_list),len(col_list)*(n_cases+1)))\n",
    "    mean_array = np.zeros((len(row_list),len(col_list)))\n",
    "    stats_array = np.zeros((len(row_list),len(col_list)*(n_cases+1)))\n",
    "\n",
    "    for j, col in enumerate(col_list):\n",
    "        for ind, case in enumerate(cases): \n",
    "\n",
    "            path = \"/Users/markolchanyi/Desktop/\" + case + \"_statistics.xlsx\"\n",
    "\n",
    "            mat, CI_mat, unique_seeds = create_correlation_matrix(path)\n",
    "\n",
    "            for i, row in enumerate(row_list):\n",
    "                out_array[i,(n_cases+1)*j + ind] = round(mat[unique_seeds.index(row),unique_seeds.index(col)],n_digits)\n",
    "                if CI_mat[unique_seeds.index(row),unique_seeds.index(col)] == 1:   \n",
    "                    stats_array[i,(n_cases+1)*j + ind] = 1\n",
    "\n",
    "        for i in range(len(row_list)):\n",
    "            avg = (out_array[i,(n_cases+1)*(j+1)-(n_cases+1)] + out_array[i,(n_cases+1)*(j+1)-n_cases] + out_array[i,(n_cases+1)*(j+1)-(n_cases-1)])/n_cases\n",
    "            mean_array[i,j] = avg  \n",
    "            std = np.std((out_array[i,(n_cases+1)*(j+1)-(n_cases+1)], out_array[i,(n_cases+1)*(j+1)-n_cases], out_array[i,(n_cases+1)*(j+1)-(n_cases-1)]))\n",
    "            out_array[i,(n_cases+1)*(j+1)-1] = round(avg,n_digits)\n",
    "            std_array[i,(n_cases+1)*(j+1)-1] = round(std,n_digits)\n",
    "\n",
    "            ### make look clean, hacky \n",
    "            if stats_array[i,(n_cases+1)*(j+1)-(n_cases+1)] + stats_array[i,(n_cases+1)*(j+1)-n_cases] + stats_array[i,(n_cases+1)*(j+1)-(n_cases-1)] == n_cases:\n",
    "                stats_array[i,(n_cases+1)*(j+1)-1] = 1\n",
    "                          \n",
    "    for i in range(out_array.shape[0]):\n",
    "        worksheet.write(i+1+row_counter,0, str(row_list[i]) , book_format_true)\n",
    "        for j in range(out_array.shape[1]):\n",
    "            worksheet.write(row_counter,j+1, str(col_list[int(math.floor(j/(n_cases+1)))]), book_format_true)\n",
    "            if stats_array[i,j] == 1:\n",
    "                if (j + 1) % (len(cases)+1) == 0 and j > 1: \n",
    "                    std = std_array[i,j]\n",
    "                    worksheet.write(i+1+row_counter, j+1, str(round(out_array[i,j],3)), book_format_true)\n",
    "                else:\n",
    "                    worksheet.write(i+1+row_counter, j+1, round(out_array[i,j],3), book_format_true)\n",
    "\n",
    "            else: \n",
    "                if (j + 1) % (len(cases)+1) == 0 and j > 1: \n",
    "                    std = std_array[i,j]\n",
    "                    worksheet.write(i+1+row_counter, j+1, str(round(out_array[i,j],3)), book_format_false)\n",
    "                else:\n",
    "                    worksheet.write(i+1+row_counter, j+1, round(out_array[i,j],3),book_format_false)\n",
    "                \n",
    "    row_counter += len(row_list) + n_cases\n",
    "          \n",
    "workbook.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1638e405",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### load raw DMN files and extract individual structural and functional conn. ####\n",
    "## for neurotransmitter-specific groups of AAN nodes ##\n",
    "\n",
    "path_DMN = \"./DMN_vol_file\"\n",
    "dmn_vol, dummy_affine = load_nifti(path_DMN, return_img=False)\n",
    "\n",
    "AAN_roi_list = [\"mRt\", \"VTA\", \"PAG\", \"PTg\", \"DR\", \"PnO\", \"PBC\", \"MnR\", \"LC\", \"LDTg\"]\n",
    "parsed_SC_list = [\"ser\", \"nor\", \"dop\", \"ace\", \"glut\"]\n",
    "parsed_SC_vals = np.zeros_like(parsed_SC_list,dtype=np.float64)\n",
    "\n",
    "atlas_label_path = \"./AAN_label_MNI_path\"\n",
    "\n",
    "for roi in parsed_SC_list: \n",
    "    if roi == \"ser\": \n",
    "        vol1,dummy_affine = load_nifti(atlas_label_path + \"MnR.nii.gz\", return_img=False)\n",
    "        vol2,dummy_affine = load_nifti(atlas_label_path + \"DR.nii.gz\", return_img=False)\n",
    "        vol1[vol1 > 0.4] = 1\n",
    "        vol1[vol2 > 0.4] = 1\n",
    "        vol1[vol1 < 0.9] = 0\n",
    "        FC_tmp = dmn_vol.copy()\n",
    "        FC_tmp[vol1 == 0] = 0\n",
    "        avg_fc_val = np.sum(FC_tmp)/np.count_nonzero(FC_tmp)\n",
    "        parsed_SC_vals[parsed_SC_list.index(roi)] = avg_fc_val\n",
    "    elif roi == \"nor\":\n",
    "        vol1,dummy_affine = load_nifti(atlas_label_path + \"LC.nii.gz\", return_img=False)\n",
    "        vol1[vol1>0.4] = 1\n",
    "        vol1[vol1<0.9] = 0\n",
    "        FC_tmp = dmn_vol.copy()\n",
    "        FC_tmp[vol1 == 0] = 0\n",
    "        avg_fc_val = np.sum(FC_tmp)/np.count_nonzero(FC_tmp)\n",
    "        parsed_SC_vals[parsed_SC_list.index(roi)] = avg_fc_val\n",
    "    elif roi == \"dop\": \n",
    "        vol1,dummy_affine = load_nifti(atlas_label_path + \"VTA.nii.gz\", return_img=False)\n",
    "        vol1[vol1>0.4] = 1\n",
    "        vol1[vol1<0.9] = 0\n",
    "        FC_tmp = dmn_vol.copy()\n",
    "        FC_tmp[vol1 == 0] = 0\n",
    "        avg_fc_val = np.sum(FC_tmp)/np.count_nonzero(FC_tmp)\n",
    "        parsed_SC_vals[parsed_SC_list.index(roi)] = avg_fc_val\n",
    "    elif roi == \"ace\": \n",
    "        vol1,dummy_affine = load_nifti(atlas_label_path + \"PTg.nii.gz\", return_img=False)\n",
    "        vol2,dummy_affine = load_nifti(atlas_label_path + \"LDTg.nii.gz\", return_img=False)\n",
    "        vol1[vol1 > 0.4] = 1\n",
    "        vol1[vol2 > 0.4] = 1\n",
    "        vol1[vol1 < 0.9] = 0\n",
    "        FC_tmp = dmn_vol.copy()\n",
    "        FC_tmp[vol1 == 0] = 0\n",
    "        avg_fc_val = np.sum(FC_tmp)/np.count_nonzero(FC_tmp)\n",
    "        parsed_SC_vals[parsed_SC_list.index(roi)] = avg_fc_val\n",
    "    elif roi == \"glut\": \n",
    "        vol1,dummy_affine = load_nifti(atlas_label_path + \"mRt.nii.gz\", return_img=False)\n",
    "        vol2,dummy_affine = load_nifti(atlas_label_path + \"PBC.nii.gz\", return_img=False)\n",
    "        vol3,dummy_affine = load_nifti(atlas_label_path + \"PnO.nii.gz\", return_img=False)\n",
    "        vol1[vol1 > 0.4] = 1\n",
    "        vol1[vol2 > 0.4] = 1\n",
    "        vol1[vol3 > 0.4] = 1\n",
    "        vol1[vol1 < 0.9] = 0\n",
    "        FC_tmp = dmn_vol.copy()\n",
    "        FC_tmp[vol1 == 0] = 0\n",
    "        avg_fc_val = np.sum(FC_tmp)/np.count_nonzero(FC_tmp)\n",
    "        parsed_SC_vals[parsed_SC_list.index(roi)] = avg_fc_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c73f566",
   "metadata": {},
   "outputs": [],
   "source": [
    "### FOR INDIVIDUAL AAN LABELS ###\n",
    "AAN_roi_list = [\"mRt\", \"VTA\", \"PAG\", \"PTg\", \"DR\", \"PnO\", \"PBC\", \"MnR\", \"LC\", \"LDTg\"]\n",
    "parsed_SC_list = AAN_roi_list\n",
    "parsed_SC_vals = np.zeros_like(parsed_SC_list,dtype=np.float64)\n",
    "\n",
    "for roi in parsed_SC_list: \n",
    "    vol1,dummy_affine = load_nifti(atlas_label_path + roi + \".nii.gz\", return_img=False)\n",
    "    vol1[vol1>0.4] = 1\n",
    "    vol1[vol1<0.9] = 0\n",
    "    FC_tmp = dmn_vol.copy()\n",
    "    FC_tmp[vol1 == 0] = 0\n",
    "    avg_fc_val = np.sum(FC_tmp)/np.count_nonzero(FC_tmp)\n",
    "    parsed_SC_vals[parsed_SC_list.index(roi)] = avg_fc_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0c08f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PLOT NEUROTRANMITTER-SPECIFIC SF PLOTS\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "# Make a scatter plot\n",
    "\n",
    "plt.plot(functional_mean_array, mean_array, 'o',c='black')\n",
    "ax.tick_params(axis=\"y\", direction='in', length=5)\n",
    "ax.tick_params(axis=\"x\", direction='in', length=5)\n",
    "plt.xlabel(\"Functional Connectivity\",fontweight=\"bold\",fontsize=12)\n",
    "plt.ylabel(\"Structural Connectivity Probability (%)\",fontweight=\"bold\",fontsize=12)\n",
    "\n",
    "for i, txt in enumerate(row_list):\n",
    "    if txt == \"Glutamate\":\n",
    "        ax.annotate(txt, (functional_mean_array[i], mean_array[i]),xytext=(10, -55), textcoords='offset pixels')\n",
    "    elif txt == \"Serotonin\":\n",
    "        ax.annotate(txt, (functional_mean_array[i], mean_array[i]),xytext=(-250, -50), textcoords='offset pixels')\n",
    "        \n",
    "    else:\n",
    "        ax.annotate(txt, (functional_mean_array[i], mean_array[i]),xytext=(0, 25), textcoords='offset pixels')\n",
    "    \n",
    "plt.savefig('./SF_neurotransmitter.png',dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ee0702",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PLOT INIDIVIAL AAN NODE SPECIFIC SF ##\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "fig,ax = plt.subplots()\n",
    "for i in range(len(functional_mean_array)):\n",
    "    plt.scatter(functional_mean_array[i], mean_array[i], color=lut_array_rgba[i])\n",
    "ax.tick_params(axis=\"y\", direction='in', length=5)\n",
    "ax.tick_params(axis=\"x\", direction='in', length=5)\n",
    "plt.xlabel(\"Functional Connectivity\",fontweight=\"bold\",fontsize=12)\n",
    "plt.ylabel(\"Structural Connectivity Probability (%)\",fontweight=\"bold\",fontsize=12)\n",
    "\n",
    "for i, txt in enumerate(row_list):\n",
    "    if txt == \"PBC\":\n",
    "        ax.annotate(txt, (functional_mean_array[i], mean_array[i]),xytext=(0, -65), textcoords='offset pixels')\n",
    "    elif txt == \"PAG\":\n",
    "        ax.annotate(txt, (functional_mean_array[i], mean_array[i]),xytext=(23, -10), textcoords='offset pixels')\n",
    "    elif txt == \"MnR\":\n",
    "        ax.annotate(txt, (functional_mean_array[i], mean_array[i]),xytext=(-125, 25), textcoords='offset pixels')\n",
    "        \n",
    "    else:\n",
    "        ax.annotate(txt, (functional_mean_array[i], mean_array[i]),xytext=(0, 25), textcoords='offset pixels')\n",
    "    \n",
    "plt.savefig('./SF_individual_nuclei.png',dpi=400)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
